# Feedback Loop Analysis: 2026-02-07 (Session 2)

## Ground Truth Status

- Resolved questions in AIB tournament: 12
- Questions with live forecasts matched to resolutions: 0 (all resolved before we forecast them)
- Retrodictions completed: 8 total (4 new in this session: 41839, 41838, 41454, 41451)
- Binary retrodiction average Brier: 0.3613 (dragged up by 41521 at 0.7225)
- **Without the bad 41521 call**: Binary Brier = 0.0001 (only 41839, which was near-certain)

## Retrodiction Results Summary

| Post ID | Question | Type | Retrodict Date | Forecast | Actual | Score | Verdict |
|---------|----------|------|---------------|----------|--------|-------|---------|
| 41839 | New START renewal | binary | 2026-02-01 | 1% | No | Brier: 0.0001 | Excellent |
| 41838 | Alphabet Q4 EMEA CC rev | numeric | 2026-01-31 | $31.3B | $31.6B | Within CI | Excellent |
| 41454 | VIX max Jan 19-30 (run 2) | numeric | 2026-01-05 | 19.5 | 20.99 | Within CI | Good |
| 41454 | VIX max Jan 19-30 (run 1) | numeric | 2026-01-05 | 18.75 | 20.99 | Within CI | Good |
| 41451 | Grammy Best Trad Country | MC | 2026-01-06 | 35% on winner | Zach Top | log: -1.05 | Decent |
| 41521 | UNGA condemn US (prior) | binary | 2026-01-11 | 85% | No | Brier: 0.72 | Bad |
| 41517 | FOMC dissenting votes (prior) | MC | 2026-01-10 | 32% on winner | 2 | log: -1.14 | Bad |
| 41747 | Zepbound Q4 rev (prior) | numeric | 2026-01-25 | $5.0B | $4.26B | Within CI | OK |

## Future-Leak Detection

All 4 new retrodictions passed future-leak checks:
- **41839**: Agent correctly forecasted as if it were Feb 1, 2026. No references to post-resolution events.
- **41838**: Agent couldn't find Q4 2025 earnings (correct — they hadn't been released on Jan 31). Used analyst estimates and historical patterns.
- **41454**: Agent used VIX data through Jan 2, 2026 only. Correctly identified FOMC meeting window as a catalyst without knowing the outcome.
- **41451**: Agent explicitly noted it couldn't find Grammy results despite the ceremony having occurred (Feb 1). Correctly used pre-ceremony evidence only (Rolling Stone predictions, nomination counts).

**Verdict**: Retrodict hooks are working correctly post-`updatedInput` fix.

## Object-Level Findings

### Reasoning Quality Assessment

**41839 (New START) — Brier 0.0001**: Near-perfect. The agent correctly identified that the treaty's formal extension mechanism was already used in 2021, only 4 days remained, and multiple expert sources confirmed no extension was coming. Strong reasoning, well-calibrated extreme confidence.

**41838 (Alphabet EMEA) — $293M off on $31.6B target**: Excellent. The agent showed sophisticated financial analysis:
- Correctly backed into Q4 2024 baseline from annual data
- Used multiple estimation methods that converged ($30.5-31.6B range)
- Correctly identified EMEA growth lagging total company growth
- Appropriate confidence intervals
- **Issue**: Spent 548 seconds (9+ minutes) with 40 tool calls — the most expensive forecast. Struggled to find quarterly EMEA breakdowns and tried many different approaches. This is a data access problem, not a reasoning problem.

**41454 (VIX) — 1.49 points off on 20.99 actual**: Good but slightly conservative. Both runs had the actual within CI. The agent ran Monte Carlo simulations incorporating mean reversion, FOMC effects, and jump risk. The second run (19.5 median) improved over the first (18.75), suggesting the agent learned to better weight catalysts.
- **Notable**: Agent correctly identified FOMC meeting timing (Jan 27-28) as a major catalyst
- **Issue**: VIX Monte Carlo simulations may systematically underestimate the upside tail. The actual 20.99 was between the 60th and 80th percentile in both runs. This is acceptable for a single observation but worth monitoring.

**41451 (Grammy) — Correct winner at 35%**: Decent for a 5-way multiple choice. The agent correctly identified Zach Top as the frontrunner based on Rolling Stone predictions and nomination counts. A 35% probability on the correct winner yields a log score of -1.05, which is better than uniform (-1.61) but not great.
- **Issue**: The agent was unable to find the actual ceremony results despite the ceremony having occurred 6 days earlier. This is a retrodict limitation (correct behavior) but the agent spent considerable time searching before accepting it couldn't know.
- **Observation**: 35% on a 5-way race means the agent thought there was a 65% chance Zach Top wouldn't win. Given Rolling Stone's explicit prediction and 3 nominations, 40-45% would have been more appropriate.

### Tool Performance

| Tool | Calls (across 4 forecasts) | Errors | Notes |
|------|---------------------------|--------|-------|
| search_exa | 33 | 0 | Workhorse. Slow (~7s avg) but reliable |
| web_search | 28 | 0 | Good complement to Exa |
| execute_code | 8 | 0 | Used for Monte Carlo (VIX, Alphabet) |
| get_metaculus_questions | 4 | 2 | 50% error rate — investigate |
| polymarket_price | 2 | 0 | Slow (~21s) but works |
| get_cp_history | 1 | 1 | 100% error — known issue in retrodict mode |
| stock_price | 1 | 0 | Used for VIX current level |
| stock_history | 4 | 0 | VIX historical data |
| wikipedia | 3 | 0 | Grammy background info |
| manifold_price | 2 | 0 | Quick (~150-470ms) |
| notes | 8 | 0 | Always works |

**Key observations**:
1. **get_metaculus_questions failing at 50%** — Needs investigation. These may be retrodict-related (question ID mismatch with post ID).
2. **polymarket_price is very slow** (21s per call) — likely API/scraping latency. Could benefit from caching or timeout reduction.
3. **search_exa dominates tool time** — 33 calls averaging 7s each = ~231s of search time across 4 forecasts. This is the primary bottleneck.
4. **get_cp_history error** — Expected in retrodict mode when filtering cuts off all data, but the error message should be more informative.

### Capability Gaps Identified

1. **No SEC filing tool**: The Alphabet forecast spent significant time trying to access SEC quarterly filings for regional revenue breakdowns. A tool that can fetch structured financial data from SEC EDGAR or financial APIs (e.g., Polygon.io, FMP) would dramatically improve earnings-related forecasts.

2. **No Grammy/awards results API**: The agent correctly couldn't find results in retrodict mode, but even in live mode, having a reliable awards database API would help.

3. **Agent doesn't anchor on question-provided data**: The Alphabet question included a linked Google Sheets spreadsheet with historical data. The agent couldn't access it (likely blocked by auth or Sheets format). Questions that provide their own data should have that data pre-extracted and included in the question context.

## CP Divergence Analysis (Live Forecasts)

From the 29 live forecasts with CP available:

**Huge divergences (>15pp):**
- **41835**: 97% vs CP 25% (+72%) — Resolved YES. **We were right, CP was wrong.** (US govt shutdown before Feb 1)
- **41906**: 88% vs CP 40% (+48%) — Still open. Trump admin reducing federal workforce.
- **41999/41987/41963/41955**: Meta-predictions, all 25-33pp above CP. These may reflect over-anchoring on underlying CP levels.

**Notable**: 41835 is our best divergence — we forecast 97% when CP was only 25%, and the government did shut down. This validates that the agent can have genuine edge over the crowd.

**Bias check**: 12 forecasts higher than CP, 11 lower. Overall bias: +8.3%. Slightly bullish on YES but not systematically so.

**Meta-prediction cluster**: 5 of the 6 largest divergences are meta-predictions ("Will CP be above X%?"). The agent consistently predicts higher than CP for these. This could be:
- Genuine insight (the agent may be correctly modeling CP drift)
- Systematic over-confidence on meta-predictions
- Need resolution data to distinguish

## Meta-Level Findings

### Is the Agent Tracking Its Own Performance Well?

**Good**:
- Structured JSON output captures all key fields (probability, factors, tool metrics, token usage)
- Retrodict comparison data automatically computed
- Session notes (structured/) capture key findings

**Gaps**:
- **No meta-reflection in retrodict mode**: The session notes (structured/*.json) contain research findings and estimates, but NOT the full meta-reflection that's normally written via `notes(write_meta)`. The agent writes meta-reflections in the logs but they're not structured/searchable.
- **No question-type tagging in forecast output**: We classify questions in the prompt (predictive/definitional/meta/measurement) but don't store this classification in the forecast JSON. This would help aggregate analysis.
- **Token usage tracking works** but we don't aggregate cost per forecast.

### Analysis Process Quality

This analysis was productive. It surfaced:
- Concrete tool failures (get_metaculus_questions 50% error rate)
- A clear capability gap (SEC filing access for earnings questions)
- Validation that retrodict hooks work
- Evidence the agent can beat CP (41835)
- A potential meta-prediction bias pattern to monitor

## Meta-Meta Findings

### feedback_collect.py Improvements Needed

1. **Rate limiting is aggressive**: The script hit 429 errors on 8+ requests during CP collection. Needs exponential backoff with longer delays between requests (e.g., 500ms between each instead of firing rapidly).

2. **No deduplication of retrodictions**: The VIX question (41454) appears twice because it was retrodicted twice. The script should use the latest retrodiction per (post_id, retrodict_date) pair.

3. **No cost estimation**: Adding token usage aggregation to the feedback output would help track spend per forecast.

### This Document Updates

No changes needed to the feedback-loop command document — it's well-structured and the phases worked well for this analysis.

## Changes Implemented

| Level | Change | File(s) | Status |
|-------|--------|---------|--------|
| Object | Rate limiting in feedback_collect.py | `.claude/plugins/aib/scripts/feedback_collect.py` | Done |
| Object | Investigated get_metaculus_questions errors | N/A (agent passes question_id instead of post_id, recoverable) | Investigated |
| Object | Added `question_category` field to ForecastOutput | `src/aib/agent/models.py`, `src/aib/agent/core.py` | Done |
| Object | Added `company_financials` tool (yfinance) | `src/aib/tools/financial.py`, `src/aib/agent/tool_policy.py` | Done |
| Object | Improved tool guide in prompts.py | `src/aib/agent/prompts.py` | Done |
| Meta | Deduplicated retrodictions in feedback_collect | `.claude/plugins/aib/scripts/feedback_collect.py` | Done |
| Meta | Deep-dived meta-prediction divergences | Analysis only — no bias found, monitoring | Done |
| Meta | Comprehensive tool inventory and usage audit | 36 tools inventoried, 7 never used | Done |

## Tool Usage Audit Results

### Tools Never Used (in any forecast)
| Tool | Available? | Why Unused |
|------|-----------|------------|
| `search_news` (AskNews) | No (missing API keys) | API key not configured |
| `search_arxiv` | Yes | Agent doesn't reach for it — no academic questions yet |
| `get_coherence_links` | Yes | Agent doesn't check related questions |
| `spawn_subquestions` | Yes | Agent prefers single-thread research |
| `google_trends_compare` | Yes | Agent uses `google_trends` alone |
| `polymarket_history` / `manifold_history` | Yes | Agent uses live prices, not historical |
| `fred_search` | Yes | Agent uses `fred_series` with known IDs |

### Tools Added
- **`company_financials`**: Quarterly/annual income statements via yfinance. No API key needed. Covers revenue, net income, EPS for any public company. Does NOT include regional breakdowns.

### Prompt Guidance Updates
- Added `search_arxiv`, `fred_search`, `company_financials`, `google_trends_related`, `polymarket_history`/`manifold_history`, `spawn_subquestions`, `get_cp_history` to the Tool Guide
- Reorganized into 7 phases (was 6) with clearer use-case triggers

## Meta-Prediction Deep Dive

Analyzed 5 meta-prediction forecasts with >15pp CP divergence. Findings:
- Agent correctly checks current CP relative to threshold
- Agent correctly considers forecaster base size (typically 700-900 forecasters = sticky)
- Reasoning is case-specific, not formulaic
- Cannot determine if calibrated without resolution data
- **Not actionable yet** — monitor when these resolve

## Key Takeaways

1. **Retrodict hooks are airtight** — All 4 new retrodictions passed future-leak checks. The `updatedInput` fix from yesterday is working correctly.

2. **Agent reasoning quality is strong** — 3 of 4 new retrodictions were excellent (New START, Alphabet, VIX). The Grammy forecast was decent but slightly underconfident on the correct winner.

3. **Financial data access was the biggest gap** — Added `company_financials` tool to provide quarterly income statements. For regional breakdowns, the agent still needs to search earnings press releases, but basic revenue/EPS data is now directly accessible.

4. **We have genuine edge** — The 41835 government shutdown call (97% vs CP 25%, resolved YES) shows the agent can outperform the crowd when it has strong reasoning.

5. **Many tools are undiscovered** — 7 tools were never used despite being available. Updated prompt guidance to improve discoverability.

6. **Meta-predictions need monitoring** — 5 of 6 largest CP divergences are meta-predictions. Reasoning looks sound but we need resolution data to confirm.
