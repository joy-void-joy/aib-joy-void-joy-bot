# Feedback Loop Analysis: 2026-02-02

## Executive Summary

**Status**: No resolved forecasts available for scoring yet.

- **Resolved Questions**: 4 questions from AIB Spring 2026 tournament have resolved
- **Our Forecasts**: 29 forecasts saved, but none overlap with the resolved questions
- **Key Finding**: We started forecasting on newer questions (post IDs 41894+) while the resolved questions have lower IDs (41517-41835). Our forecasts haven't had time to resolve yet.

This analysis focuses on process quality and identifies improvements based on meta-reflections and code review.

## Forecasting Coverage

### Resolved Questions We Missed
1. **41835**: "Will the US government enter a shutdown before February 1, 2026?" → **yes**
2. **41746**: "Q4 2025 global revenue for Mounjaro?" → **annulled**
3. **41521**: "UN General Assembly resolution condemning US operation in V..." → **no**
4. **41517**: "Dissenting votes at January 28 FOMC meeting?" → **2**

### Recommendation
The bot should prioritize questions closer to resolution when selecting which to forecast. Questions with earlier close dates provide faster feedback loops.

## Process Quality Analysis

Based on reviewing 29 forecasts and their meta-reflections:

### Strengths

1. **Structured Reasoning**: Forecasts consistently include:
   - Clear factor decomposition with logit values
   - Confidence weighting on each factor
   - "Nothing Ever Happens" calibration explicitly applied

2. **Research Depth**: Meta-reflections show systematic research:
   - Multiple source types consulted (Wikipedia, news, prediction markets)
   - Historical base rates calculated when applicable
   - Monte Carlo simulations used for numeric questions

3. **Self-Awareness**: Reflections honestly identify:
   - Tool failures (403 errors, blocked sites)
   - Missing data sources
   - Uncertainty levels

### Weaknesses & Improvement Areas

#### 1. Tool Reliability Issues

**Observed problems:**
- WebFetch 403 errors on some sites (Tesla IR, TradingEconomics)
- Some parallel tool call failures ("sibling tool call errors")
- Polymarket search failures in some cases

**Recommendation**: Add retry logic with alternative search strategies when primary tools fail. Consider adding backup data sources.

#### 2. Missing Data Sources

Frequently mentioned missing capabilities:
- **FRED API access**: Historical time series data (not just current page)
- **China CPCA monthly sales data**: Leading indicator for auto forecasts
- **European registration databases**: Vehicle sales leading indicators
- **Direct market data APIs**: Yahoo Finance, Bloomberg-like access

**Recommendation**: Add MCP tools for:
```python
# Priority additions
- fred_historical_data(series_id, start_date, end_date)
- google_trends_data(keyword, timeframe)  # Currently forecasting GT questions
- financial_data(ticker, metric, timeframe)
```

#### 3. Subagent Underutilization

Meta-reflections frequently note: "Did not use subagents for this relatively straightforward question."

This suggests:
- Most questions are being handled in the main thread
- Subagent spawning overhead may be too high
- The threshold for "needs subagent" is too high

**Recommendation**: Lower the bar for using quick-researcher (Haiku) for initial orientation. It's cheap and fast.

#### 4. Market Signal Integration

Prediction market data is being gathered but integration is informal:
- Kalshi, Manifold, Polymarket prices mentioned
- No systematic weighting or ensemble approach

**Recommendation**: Add a market_ensemble tool that:
1. Queries all available markets for related questions
2. Returns weighted average (by volume/liquidity)
3. Flags significant disagreements

#### 5. Google Trends Forecasting

Several questions ask about Google Trends values. Current approach:
- Search for recent news events
- Qualitative reasoning about decay patterns
- No direct Trends data access

**Recommendation**: Add google_trends_data tool that fetches actual trend values to establish starting points and historical patterns.

## Code Improvements

### 1. feedback_collect.py Fix

**Completed**: Updated to use local `metaculus` package instead of missing `forecasting_tools`:
- Changed imports from `forecasting_tools` to local `metaculus`
- Made client async-compatible with `AsyncMetaculusClient`
- Fixed `typed_resolution` → `resolution_string` parsing

### 2. Priority Queue for Questions

Add question prioritization logic in `cli.py`:
```python
def priority_score(question):
    """Higher score = forecast first."""
    days_to_close = (question.close_time - datetime.now()).days
    # Prefer questions closing soon (faster feedback)
    return -days_to_close
```

### 3. Tool Error Handling

Current: Tools return `is_error=True` on failure
Improvement: Add automatic retry with alternative approach
```python
# In forecasting tools
if primary_search_failed:
    # Try alternative search strategy
    return fallback_search(query)
```

## Prompt Improvements

### 1. Add Question Selection Guidance

Add to system prompt:
```
## Question Selection
When forecasting multiple questions, prioritize:
1. Questions closing soonest (faster feedback loop)
2. Binary questions (cleaner scoring)
3. Questions with prediction market data available
```

### 2. Strengthen Market Integration

Add to system prompt:
```
## Market Price Weighting
- High volume (>$10k Polymarket, >1000 traders Manifold): Weight heavily
- Medium volume: Use as sanity check
- Low volume (<$1k or <50 traders): Treat as single data point
- Large disagreement between markets: Investigate why
```

### 3. Numeric Question Guidance

Current guidance is good but could add:
```
## Numeric Percentile Sanity Checks
Before submitting percentiles, verify:
- 10th and 90th differ by at least 30% of median (avoid overconfidence)
- All values respect question bounds
- Distribution shape matches question type (log-normal for prices, normal for counts)
```

## Next Steps

1. **Track Resolution Dates**: Monitor when current forecasts will resolve
2. **Build Calibration Baseline**: Once 10+ forecasts resolve, calculate Brier scores
3. **Implement Tool Additions**: Start with Google Trends and FRED historical data
4. **Adjust Question Selection**: Prioritize faster-resolving questions

## Questions to Investigate

1. **Base Rate Quality**: Are the base rates calculated by deep-researcher well-calibrated?
2. **"Nothing Ever Happens" Magnitude**: Is the -0.5 to -1.5 logit adjustment appropriate?
3. **Factor Independence**: Are factors being double-counted?
4. **Subagent JSON Parsing**: Are subagent outputs being correctly integrated?

---

*Analysis conducted: 2026-02-02 21:25 UTC*
*Forecasts analyzed: 29*
*Resolved forecasts: 0 (none overlap with our predictions)*
