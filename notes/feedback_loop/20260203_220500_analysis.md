# Feedback Loop Analysis: 2026-02-03 (Revised)

## Ground Truth Status

- **Resolved forecasts with our predictions**: 0
- **Average Brier score**: None yet (no resolved data)

This is critical: without resolution data, CP divergence is a WEAK signal. We cannot know if our divergences represent an edge or miscalibration until questions resolve.

## Data Summary

- **Forecasts analyzed**: 47
- **Meta-reflections**: 47
- **CP comparisons**: 17 (informational only)
- **Average CP divergence**: +5.9% (we forecast higher than CP)

## Object-Level Findings

### Tool Failures (from meta-reflections)

| Tool | Failure | Count | Fix |
|------|---------|-------|-----|
| WebFetch | Yahoo Finance (JS-heavy) | 5+ | ✅ Added stock_price, stock_history tools |
| WebFetch | TradingEconomics (403/405) | 5+ | ⏸️ Needs dedicated tool or API |
| Wikipedia | Empty extract (redirects) | 2 | ✅ Added redirects=1 param |
| get_coherence_links | 404 errors | 1 | ⏸️ Needs investigation |

### Capability Gaps (agent's own words)

- "Template for FRED value on date X questions would be useful" → Future work
- "Real-time Metaculus CP tracker would be useful" → Not possible (AIB rule)
- "WebFetch failed on Yahoo Finance (JS-heavy page)" → ✅ Fixed with yfinance

### Changes Made (Following Bitter Lesson: Capabilities > Rules)

1. **Added stock_price tool** - Current price, previous close, 52-week range via Yahoo Finance
2. **Added stock_history tool** - Historical OHLCV data with configurable periods
3. **Fixed Wikipedia redirects** - Added `redirects=1` param to follow redirects
4. **Removed prescriptive prompt rules** - Deleted specific "subtract X logits" guidance
5. **Kept general principles** - "Resolution happens in someone else's mind"

## Meta-Level Findings

### Meta-Reflection Quality

The meta-reflections are useful for identifying tool failures and capability gaps. However:
- "Effort: ~N tool calls" is subjective (should be programmatic)
- No link between meta-reflection and actual tool call logs

### Tracking Improvements Needed

- Link forecast files to tool call traces
- Add programmatic cost/time tracking
- Store actual tool call counts, not estimates

## Meta-Meta Findings

### What I Did Wrong Initially

1. **Over-relied on CP divergence** - Treated it as primary signal when it's weak without resolutions
2. **Added prescriptive prompt patches** - "Subtract 0.5 logits when X" violates bitter lesson
3. **Didn't build tools first** - Should have added stock tools before any prompt changes

### What Scripts Would Help

- `trace_forecast.py` - Link forecast to full tool call trace
- `tool_failure_report.py` - Aggregate failures by tool and target
- `compare_resolution.py` - Show reasoning vs actual outcome after resolution

### Process Changes for Next Time

- Start with "What tools fail?" before "What patterns show in CP?"
- Build capabilities before changing prompts
- Wait for resolutions before concluding calibration issues

## Changes Made

| Level | Change | Rationale |
|-------|--------|-----------|
| Object | Added stock_price, stock_history tools | Agent said "WebFetch failed on Yahoo Finance" |
| Object | Fixed Wikipedia redirects | Agent got empty extracts for redirect titles |
| Object | Removed prescriptive logit rules | Bitter lesson: capabilities > rules |
| Process | Rewrote feedback-loop command | Three-level analysis, capability-first |

## Validation Plan

| Change | How to Validate | When |
|--------|-----------------|------|
| Stock tools | Agent uses them instead of WebFetch | Next forecasts |
| Wikipedia fix | No more "403 error" in meta-reflections | Next forecasts |
| Prompt simplification | Agent reasoning quality unchanged | After resolutions |

## Next Steps

1. **Wait for resolutions** (Feb 15) - Q41955, Q41963, Q41906
2. **Re-run feedback loop** with Brier score data
3. **Build TradingEconomics tool** if failures continue
4. **Add programmatic tracking** to meta-reflections
