# Feedback Loop Analysis: 2026-02-03

## Ground Truth Status

- **Resolved forecasts with our predictions**: 0
- **Average Brier score**: None - no resolution data yet
- **Forecasts with CP comparison**: 17
- **Average CP divergence**: +6.3% (we forecast higher than CP on average)

## Data Used

This analysis used:
1. **`notes/feedback_loop/20260203_233716_metrics.json`** - CP comparisons for 17 forecasts
2. **`logs/`** - Full reasoning traces for high-divergence questions (previously underutilized)
3. **`notes/meta/`** - 47 meta-reflections with tool effectiveness notes

## Key Findings

### Large CP Divergences (>15pp)

| Question | Our Forecast | CP | Divergence | Type | Assessment |
|----------|-------------|-----|------------|------|------------|
| 41906 (Trump NYC funding) | 88% | 40% | +48pp | Predictive | Reasoning sound - cited specific EOs, HHS freeze, DOJ list |
| 41987 (AI Billboard meta) | 78% | 45% | +33pp | Meta-prediction | Reasoning sound - CP already above threshold |
| 41963 (EU verification meta) | 72% | 45% | +27pp | Meta-prediction | Reasoning sound - forecaster base stability argument |
| 41955 (EU verification meta) | 70% | 45% | +25pp | Meta-prediction | Reasoning sound - upward trend, large forecaster base |

**Pattern**: All high-divergence forecasts show sound reasoning when full logs are read. Three of four are meta-predictions about CP movements, where the agent's logic about forecaster base stability appears reasonable.

### Trace Analysis: Q41906 (Largest Divergence)

Read full log at `logs/41906/20260202_001600.log`. The agent:
1. Correctly identified EO 14287 (April 2025) naming NYC on sanctuary list
2. Found HHS funding freeze (Jan 5-6, 2026) affecting NY state funds
3. Noted question asks about "initiation" regardless of legal outcomes
4. Weighed state-level vs city-specific targeting correctly

The reasoning is thorough and evidence-based. The 48pp divergence reflects an information edge (specific formal actions found), not reasoning error. Cannot evaluate accuracy without resolution.

### Tool Failures (from meta-reflections)

| Tool/Target | Failure Type | Count | Existing Fix? |
|-------------|-------------|-------|---------------|
| Wikipedia | 403 errors | 3+ | No |
| TradingEconomics | 403/405 errors | 6+ | N/A - use FRED |
| Yahoo Finance | JS rendering | 3+ | ✅ `stock_price` tool exists |
| get_coherence_links | 404 errors | 2+ | Need investigation |
| Polymarket search | Poor results | 2+ | Exists but needs improvement |

### Agent Capability Requests (Direct Quotes)

1. **"Would benefit from a tool that shows CP history over time for a question"** - Requested multiple times for meta-predictions
2. **"A dedicated financial data tool that can fetch real-time stock prices"** - ✅ Already exists (`stock_price`, `stock_history`)
3. **"Would love a 'get FRED historical data' tool"** - ✅ Already exists (`fred_series`, `fred_search`)
4. **"For Google Trends questions specifically, having a tool that can directly query Google Trends API would be valuable"**

**Finding**: Agent doesn't know about some existing tools. This is a discoverability issue, not a capability gap.

## Changes Made

### 1. Updated feedback-loop.md to use logs/

Added section 2a "Read Full Reasoning Traces (logs/)" before meta-reflections, emphasizing that:
- `logs/<question_id>/*.log` contains actual reasoning traces
- These are more detailed than meta-reflection summaries
- For large divergences, read the full log to understand reasoning

```bash
git diff .claude/commands/feedback-loop.md
```

## What I Did NOT Do (Correctly)

- Did not add prompt rules for meta-predictions or high-divergence questions
- Did not tell agent to "trust CP" or adjust based on divergence
- Did not patch specific patterns (bitter lesson)

## Recommendations for Next Session

### Priority 1: Tool Discoverability

The agent explicitly requests tools that already exist (FRED, stock prices). Options:
1. Add tool names to the agent prompt's tool listing
2. Create a "tool discovery" subagent
3. Improve tool documentation in prompts

### Priority 2: Build CP History Tool

Agent requested this multiple times for meta-predictions. Implementation:
1. Add `get_cp_history(question_id)` tool to forecasting.py
2. Use Metaculus API to fetch historical CP over time
3. Return as time series for trend analysis

### Priority 3: Fix Wikipedia 403 Errors

Investigate and fix the Wikipedia fetch failures.

### Priority 4: Investigate get_coherence_links 404s

The coherence links tool returns 404 errors. Check if:
- API endpoint changed
- Authentication required
- Method name is wrong (per CLAUDE.md note)

## Process Improvement

**Updated feedback-loop.md** to prioritize reading `logs/` traces before aggregate analysis. The logs contain the actual reasoning the agent performed, not just summaries.

## Key Learnings

1. **CP divergence without resolution tells us WHERE reasoning differs, not WHETHER it's wrong**
2. **Full reasoning traces in `logs/` are more valuable than meta-reflection summaries**
3. **Tool discoverability may be limiting agent capability more than missing tools**
4. **Meta-prediction divergences follow a coherent pattern (forecaster base stability)**
